# Triton-Ascend 高性能矩阵乘法算子

## 项目介绍

本项目基于 Triton 框架，针对 Ascend NPU 硬件特性持续优化矩阵乘法算子，在 V4 版本并行化与参数调优的基础上，新增 **Split-K 双阶段优化**，彻底解决了 K_SPLITS 功能退化问题，进一步突破大尺寸矩阵与长瘦矩阵的计算瓶颈。核心目标是通过硬件感知的分块策略、并行化改造与智能调优，实现全场景矩阵乘法的高性能计算，尤其适配超大矩阵、高维度矩形矩阵及长瘦特殊矩阵。

### 核心背景

Ascend NPU 片上缓存有限，传统矩阵乘法依赖分块技术（Tiling）适配存储，但存在 K 维度并行失效、大矩阵访存带宽不足、长瘦矩阵负载不均等问题。本项目通过多版本迭代（V1~V5），逐步优化：从基础配置→Autotune 调优→NPU 并行写回→K 轴并行→Split-K 双阶段计算，最终实现关键场景性能飞跃。

## 核心功能

1. **全版本算子支持**：提供 5 个迭代版本，覆盖从基线到极致优化的全场景需求（V1~V5）。
2. **Split-K 双阶段计算**：新增 Split-K 算法，通过「并行计算 + 结果归并」两阶段逻辑，让 K_SPLITS 真正发挥作用，最大化 K 维度并行度。
3. **智能参数调优**：优化循环展开因子（S_UNROLL=8）、并行写回分块数（4）、K 轴拆分次数（K_SPLITS=4），平衡延迟隐藏与资源占用。
4. **长瘦矩阵深度适配**：针对 M/N 维度差异显著的矩阵，采用非对称分块与长轴优先策略，抑制短维度调度开销。
5. **Autotune 自动适配**：扩展分块配置空间（11 种分块组合），自动匹配不同矩阵形状与硬件环境的最优参数。
6. **完整性能验证**：内置多版本对比测试脚本，支持 10 种矩阵形状的性能量化与结果校验。

## 快速开始

### 环境依赖

- 硬件：Ascend NPU（支持 Triton 框架适配）

- 软件：

  - Python 3.8+
  - Triton 2.0+
  - PyTorch 1.18+
  - torch_npu（Ascend PyTorch 适配库）
  - pandas（性能测试统计）

  

### 安装步骤

1. 安装 Ascend NPU 驱动及基础软件栈

2. 安装依赖包：

   ```
   pip install triton torch torch_npu pandas
   ```

   

3. 克隆本项目代码并进入目录：

   ```
   git clone <项目仓库地址>
   cd triton-ascend-matmul
   ```

   

### 快速使用示例

```python
import torch
import torch_npu
from matmul_kernel import (
    matmul_wrapper, 
    matmul_wrapper_splitK,
    KERNEL_V4_KPAR,
    KERNEL_V5_SplitK  # 新增 Split-K 优化核
)

# 配置 Ascend NPU 设备
torch.npu.set_device(0)

# 生成测试矩阵（超大矩阵/长瘦矩阵效果最佳）
a = torch.randn((4096, 8192), dtype=torch.float16, device="npu")
b = torch.randn((8192, 4096), dtype=torch.float16, device="npu")

# 方式 1：使用 V4 版本（K 轴并行）
c_v4 = matmul_wrapper(a, b, kernel_func=KERNEL_V4_KPAR)

# 方式 2：使用 V5 版本（Split-K 双阶段优化，推荐大矩阵）
c_v5 = matmul_wrapper_splitK(a, b, kernel_func=KERNEL_V5_SplitK)

# 验证结果（与 PyTorch 原生实现对比）
c_torch = torch.matmul(a, b)
print(f"V5 版本结果误差: {(c_v5 - c_torch).abs().max().item()}")
```

### 一键性能测试

运行内置测试脚本，自动对比多版本性能：

```
python matmul_kernel.py
```

测试将覆盖 10 种矩阵形状，输出各版本平均运行时间及与基线的提速比。

## 详细使用说明

### 核心 API 说明

|                            函数名                            |     功能描述      |                   参数说明                    |  适用版本   |
| :----------------------------------------------------------: | :---------------: | :-------------------------------------------: | :---------: |
|             `matmul_wrapper(a, b, kernel_func)`              | 基础矩阵乘法入口  |      `kernel_func`: 选择 V1~V4 版本算子       | V1/V2/V3/V4 |
|          `matmul_wrapper_splitK(a, b, kernel_func)`          | Split-K 优化入口  | `kernel_func`: 仅支持 V5 版本（Split-K 算子） |     V5      |
| `create_kernel(name, autotune_configs, parallel, k_splits)`  |   创建基础算子    |  `k_splits`: K 轴并行拆分次数（最大支持 2）   |    V1~V4    |
| `create_kernel_SplitK(name, autotune_configs, parallel, k_splits)` | 创建 Split-K 算子 |    `k_splits`: K 轴拆分次数（最大支持 4）     |     V5      |

### 内置算子版本对比

|        版本         |            核心特性            |      适用场景       | 提速效果（相对 V1） |
| :-----------------: | :----------------------------: | :-----------------: | :-----------------: |
|     V1_Baseline     |       基础分块 + 无并行        |      功能验证       |    1.0x（基线）     |
|   V2_Opt_Autotune   |    全量分块配置 + Autotune     |      中小矩阵       |      1.2~1.5x       |
| V3_Opt_NPU_Parallel |      基础配置 + 并行写回       |      中等矩阵       |      1.3~1.6x       |
|  V4_Opt_Full_KPAR   | 全量配置 + 并行写回 + K 轴并行 |     中大型矩阵      |      1.8~2.3x       |
| V5_Opt_Full_SplitK  |   Split-K 双阶段 + 全量优化    | 超大矩阵 / 长瘦矩阵 |      2.0~3.5x       |

### 支持的矩阵形状

扩展至 10 种测试形状，覆盖不同场景：

- 小方阵：512x512x512
- 中方阵：2048x2048x2048
- 大方阵：4096x4096x4096
- 矩形矩阵：2048x1024x4096、4096x4096x1024、4096x8192x4096
- 长瘦矩阵：4096x32x4096、2048x32x2048、4096x32x2048

### 关键参数配置

|       参数名       |      作用      |     最优值      | 版本限制 |                  说明                  |
| :----------------: | :------------: | :-------------: | :------: | :------------------------------------: |
|     `S_UNROLL`     |  循环展开因子  |        8        |  全版本  | 平衡指令并行与资源占用，避免延迟或溢出 |
|  `并行写回分块数`  | 内存写回并行度 |        4        | V3/V4/V5 |       适配 NPU 4 个并行处理单元        |
|     `K_SPLITS`     |  K 轴拆分次数  | 4（V5）/2（V4） |  V4/V5   |    V5 突破硬件限制，支持最大 4 拆分    |
| `AUTOTUNE_CONFIGS` |  分块配置空间  |    11 种组合    | V2/V4/V5 |    新增小尺寸分块，适配更多矩阵形状    |

## 核心优化细节

### 1. Split-K 双阶段优化（V5 新增）

解决了 V4 版本 K_SPLITS 退化问题，通过两阶段逻辑实现真正的 K 轴并行：

- **Stage 1（并行计算）**：`matmul_splitk_stage1` 函数将 K 维度拆分为 `K_SPLITS` 个子任务，每个线程块处理一部分 K 子块，计算部分结果并写入中间缓冲区 `c_partial_ptr`。
- **Stage 2（结果归并）**：`matmul_splitk_stage2` 函数遍历所有 K 拆分的部分结果，累加得到完整矩阵，避免并行冲突。
- **关键设计**：使用 3D 中间缓冲区存储部分结果，通过 `pid_k` 分配线程 ID，确保并行安全性。

### 2. 参数优化原理

- **K_SPLITS=4**：V5 突破硬件限制，拆分次数从 2 提升至 4，进一步提升 K 维度并行度，尤其适配 K 维度超大的矩阵（如 4096x8192x4096）。
- **分块配置扩展**：新增 5 种小尺寸分块（如 32x32x32、32x64x32），适配小矩阵与长瘦矩阵的分块需求。

### 3. 长瘦矩阵优化策略

- 长轴（如 M 轴）采用大分块 + 高并行，最大化缓存利用率与计算并行度。
- 短轴（如 N=32）采用小分块 + 少并行，抑制线程调度与同步开销。
- 通过 Split-K 算法解决长轴访存延迟瓶颈，提升整体吞吐量。

## 性能表现

### 多版本性能对比（平均运行时间 / 提速比）

|    矩阵形状    | V1 基线  | V4 优化版 | V5 Split-K 版 | V5/V4 提速比 | V5/V1 提速比 |
| :------------: | :------: | :-------: | :-----------: | :----------: | :----------: |
|  512x512x512   | 0.271 ms | 0.287 ms  |   0.411 ms    |    0.70x     |    0.66x     |
| 2048x2048x2048 | 0.820 ms | 0.528 ms  |   0.489 ms    |    1.08x     |    1.68x     |
| 4096x4096x4096 | 4.265 ms | 2.310 ms  |   1.421 ms    |    1.63x     |    2.99x     |
| 4096x8192x4096 | 7.928 ms | 4.287 ms  |   1.954 ms    |    2.19x     |    4.06x     |
|  4096x32x4096  | 1.096 ms | 0.657 ms  |   1.008 ms    |    0.65x     |    1.09x     |

### 关键结论

1. **V5 版本优势**：超大矩阵（如 4096x8192x4096）提速比达 2.19x（相对 V4）、4.06x（相对 V1）；超大方阵（4096x4096x4096）提速 1.63x（相对 V4）。
2. **负收益场景**：小矩阵（512x512x512）、短 N 维度矩阵（N=32）因 Split-K 两阶段调度开销，性能略降，需根据矩阵尺寸动态选择算子版本。
3. **稳定性**：所有版本算子与 PyTorch 原生实现结果误差小于 1e-2，满足精度要求。

## 项目亮点与不足

### 亮点

1. **Split-K 算法突破**：成功解决 V4 版本 K_SPLITS 退化问题，设计双阶段算子，K 轴拆分次数从 2 提升至 4。
2. **全场景适配**：扩展 11 种分块配置与 10 种测试矩阵，覆盖小 / 中 / 大 / 长瘦 / 矩形全场景。
3. **工程化完善**：提供统一 API 与性能测试脚本，支持一键对比多版本效果，便于落地使用。
4. **参数量化优化**：通过大量实验确定最优参数组合（S_UNROLL=8、写回分块数 = 4、K_SPLITS=4），平衡性能与资源。

### 不足

1. **小矩阵适配不足**：Split-K 两阶段调度开销导致小矩阵性能负收益，缺乏动态开关机制。
2. **K_SPLITS 上限**：受 Ascend NPU 硬件限制，K_SPLITS 最大仅支持 4，无法进一步提升并行度。
3. **无动态调优**：未实现矩阵形状感知的自动版本选择，需用户手动根据矩阵尺寸选择 V4/V5。

## 未来计划

1. **动态版本选择**：新增形状感知逻辑，自动根据矩阵尺寸（如 M/K/N 是否大于 2048）切换 V4/V5 版本。
2. **突破硬件限制**：探索 NPU 资源调度优化，尝试将 K_SPLITS 提升至 8，进一步挖掘并行潜力。
3. **精度优化**：支持 float32 数据类型，适配更高精度计算场景。
4. **更多激活函数**：扩展支持 ReLU、GELU 等常用激活函数，提升算子通用性。

## 团队信息

- 小组成员：王淇辉、袁谦朗、何熙然、娄彦轩
- 项目定位：Ascend NPU 高性能计算优化实践，聚焦矩阵乘法算子的全场景性能提升

## 致谢

感谢 Triton 框架生态与 Ascend NPU 硬件支持，本项目基于开源技术与硬件特性进行优化，欢迎交流与贡献代码！
